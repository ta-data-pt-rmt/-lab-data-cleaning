{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Import users table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  year  month element    d1    d2    d3    d4    d5    d6  ...  \\\n",
      "0   MX17004  2010      1    tmax   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "1   MX17004  2010      1    tmin   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "2   MX17004  2010      2    tmax   NaN  27.3  24.1   NaN   NaN   NaN  ...   \n",
      "3   MX17004  2010      2    tmin   NaN  14.4  14.4   NaN   NaN   NaN  ...   \n",
      "4   MX17004  2010      3    tmax   NaN   NaN   NaN   NaN  32.1   NaN  ...   \n",
      "5   MX17004  2010      3    tmin   NaN   NaN   NaN   NaN  14.2   NaN  ...   \n",
      "6   MX17004  2010      4    tmax   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "7   MX17004  2010      4    tmin   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "8   MX17004  2010      5    tmax   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "9   MX17004  2010      5    tmin   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "10  MX17004  2010      6    tmax   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "11  MX17004  2010      6    tmin   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "12  MX17004  2010      7    tmax   NaN   NaN  28.6   NaN   NaN   NaN  ...   \n",
      "13  MX17004  2010      7    tmin   NaN   NaN  17.5   NaN   NaN   NaN  ...   \n",
      "14  MX17004  2010      8    tmax   NaN   NaN   NaN   NaN  29.6   NaN  ...   \n",
      "15  MX17004  2010      8    tmin   NaN   NaN   NaN   NaN  15.8   NaN  ...   \n",
      "16  MX17004  2010     10    tmax   NaN   NaN   NaN   NaN  27.0   NaN  ...   \n",
      "17  MX17004  2010     10    tmin   NaN   NaN   NaN   NaN  14.0   NaN  ...   \n",
      "18  MX17004  2010     11    tmax   NaN  31.3   NaN  27.2  26.3   NaN  ...   \n",
      "19  MX17004  2010     11    tmin   NaN  16.3   NaN  12.0   7.9   NaN  ...   \n",
      "20  MX17004  2010     12    tmax  29.9   NaN   NaN   NaN   NaN  27.8  ...   \n",
      "21  MX17004  2010     12    tmin  13.8   NaN   NaN   NaN   NaN  10.5  ...   \n",
      "\n",
      "    d22   d23  d24   d25   d26   d27   d28   d29   d30   d31  \n",
      "0   NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN  27.8   NaN  \n",
      "1   NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN  14.5   NaN  \n",
      "2   NaN  29.9  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "3   NaN  10.7  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "4   NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "5   NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "6   NaN   NaN  NaN   NaN   NaN  36.3   NaN   NaN   NaN   NaN  \n",
      "7   NaN   NaN  NaN   NaN   NaN  16.7   NaN   NaN   NaN   NaN  \n",
      "8   NaN   NaN  NaN   NaN   NaN  33.2   NaN   NaN   NaN   NaN  \n",
      "9   NaN   NaN  NaN   NaN   NaN  18.2   NaN   NaN   NaN   NaN  \n",
      "10  NaN   NaN  NaN   NaN   NaN   NaN   NaN  30.1   NaN   NaN  \n",
      "11  NaN   NaN  NaN   NaN   NaN   NaN   NaN  18.0   NaN   NaN  \n",
      "12  NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "13  NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "14  NaN  26.4  NaN  29.7   NaN   NaN   NaN  28.0   NaN  25.4  \n",
      "15  NaN  15.0  NaN  15.6   NaN   NaN   NaN  15.3   NaN  15.4  \n",
      "16  NaN   NaN  NaN   NaN   NaN   NaN  31.2   NaN   NaN   NaN  \n",
      "17  NaN   NaN  NaN   NaN   NaN   NaN  15.0   NaN   NaN   NaN  \n",
      "18  NaN   NaN  NaN   NaN  28.1  27.7   NaN   NaN   NaN   NaN  \n",
      "19  NaN   NaN  NaN   NaN  12.1  14.2   NaN   NaN   NaN   NaN  \n",
      "20  NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "21  NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "\n",
      "[22 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "users_table = pd.read_csv(r\"C:\\Users\\hilu1\\ironhack\\week2\\lab-data-cleaning\\weather-raw.csv\")\n",
    "print(users_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Rename Id column to userId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'year', 'month', 'element', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6',\n",
      "       'd7', 'd8', 'd9', 'd10', 'd11', 'd12', 'd13', 'd14', 'd15', 'd16',\n",
      "       'd17', 'd18', 'd19', 'd20', 'd21', 'd22', 'd23', 'd24', 'd25', 'd26',\n",
      "       'd27', 'd28', 'd29', 'd30', 'd31'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "users_table.rename(columns={'Id': 'userId'}, inplace=True)\n",
    "print(users_table.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Import posts table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  year  month element    d1    d2    d3    d4    d5    d6  ...  \\\n",
      "0   MX17004  2010      1    tmax   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "1   MX17004  2010      1    tmin   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "2   MX17004  2010      2    tmax   NaN  27.3  24.1   NaN   NaN   NaN  ...   \n",
      "3   MX17004  2010      2    tmin   NaN  14.4  14.4   NaN   NaN   NaN  ...   \n",
      "4   MX17004  2010      3    tmax   NaN   NaN   NaN   NaN  32.1   NaN  ...   \n",
      "5   MX17004  2010      3    tmin   NaN   NaN   NaN   NaN  14.2   NaN  ...   \n",
      "6   MX17004  2010      4    tmax   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "7   MX17004  2010      4    tmin   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "8   MX17004  2010      5    tmax   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "9   MX17004  2010      5    tmin   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "10  MX17004  2010      6    tmax   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "11  MX17004  2010      6    tmin   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "12  MX17004  2010      7    tmax   NaN   NaN  28.6   NaN   NaN   NaN  ...   \n",
      "13  MX17004  2010      7    tmin   NaN   NaN  17.5   NaN   NaN   NaN  ...   \n",
      "14  MX17004  2010      8    tmax   NaN   NaN   NaN   NaN  29.6   NaN  ...   \n",
      "15  MX17004  2010      8    tmin   NaN   NaN   NaN   NaN  15.8   NaN  ...   \n",
      "16  MX17004  2010     10    tmax   NaN   NaN   NaN   NaN  27.0   NaN  ...   \n",
      "17  MX17004  2010     10    tmin   NaN   NaN   NaN   NaN  14.0   NaN  ...   \n",
      "18  MX17004  2010     11    tmax   NaN  31.3   NaN  27.2  26.3   NaN  ...   \n",
      "19  MX17004  2010     11    tmin   NaN  16.3   NaN  12.0   7.9   NaN  ...   \n",
      "20  MX17004  2010     12    tmax  29.9   NaN   NaN   NaN   NaN  27.8  ...   \n",
      "21  MX17004  2010     12    tmin  13.8   NaN   NaN   NaN   NaN  10.5  ...   \n",
      "\n",
      "    d22   d23  d24   d25   d26   d27   d28   d29   d30   d31  \n",
      "0   NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN  27.8   NaN  \n",
      "1   NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN  14.5   NaN  \n",
      "2   NaN  29.9  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "3   NaN  10.7  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "4   NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "5   NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "6   NaN   NaN  NaN   NaN   NaN  36.3   NaN   NaN   NaN   NaN  \n",
      "7   NaN   NaN  NaN   NaN   NaN  16.7   NaN   NaN   NaN   NaN  \n",
      "8   NaN   NaN  NaN   NaN   NaN  33.2   NaN   NaN   NaN   NaN  \n",
      "9   NaN   NaN  NaN   NaN   NaN  18.2   NaN   NaN   NaN   NaN  \n",
      "10  NaN   NaN  NaN   NaN   NaN   NaN   NaN  30.1   NaN   NaN  \n",
      "11  NaN   NaN  NaN   NaN   NaN   NaN   NaN  18.0   NaN   NaN  \n",
      "12  NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "13  NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "14  NaN  26.4  NaN  29.7   NaN   NaN   NaN  28.0   NaN  25.4  \n",
      "15  NaN  15.0  NaN  15.6   NaN   NaN   NaN  15.3   NaN  15.4  \n",
      "16  NaN   NaN  NaN   NaN   NaN   NaN  31.2   NaN   NaN   NaN  \n",
      "17  NaN   NaN  NaN   NaN   NaN   NaN  15.0   NaN   NaN   NaN  \n",
      "18  NaN   NaN  NaN   NaN  28.1  27.7   NaN   NaN   NaN   NaN  \n",
      "19  NaN   NaN  NaN   NaN  12.1  14.2   NaN   NaN   NaN   NaN  \n",
      "20  NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "21  NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "\n",
      "[22 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming the CSV file is located at the specified path\n",
    "file_path = r\"C:\\Users\\hilu1\\ironhack\\week2\\lab-data-cleaning\\weather-raw.csv\"\n",
    "\n",
    "# Import the CSV file into a pandas DataFrame\n",
    "posts_table = pd.read_csv(file_path)\n",
    "\n",
    "# Print the DataFrame to verify the import\n",
    "print(posts_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Rename Id column to postId and OwnerUserId to userId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  year  month element    d1    d2    d3    d4    d5    d6  ...  \\\n",
      "0   MX17004  2010      1    tmax   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "1   MX17004  2010      1    tmin   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "2   MX17004  2010      2    tmax   NaN  27.3  24.1   NaN   NaN   NaN  ...   \n",
      "3   MX17004  2010      2    tmin   NaN  14.4  14.4   NaN   NaN   NaN  ...   \n",
      "4   MX17004  2010      3    tmax   NaN   NaN   NaN   NaN  32.1   NaN  ...   \n",
      "5   MX17004  2010      3    tmin   NaN   NaN   NaN   NaN  14.2   NaN  ...   \n",
      "6   MX17004  2010      4    tmax   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "7   MX17004  2010      4    tmin   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "8   MX17004  2010      5    tmax   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "9   MX17004  2010      5    tmin   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "10  MX17004  2010      6    tmax   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "11  MX17004  2010      6    tmin   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "12  MX17004  2010      7    tmax   NaN   NaN  28.6   NaN   NaN   NaN  ...   \n",
      "13  MX17004  2010      7    tmin   NaN   NaN  17.5   NaN   NaN   NaN  ...   \n",
      "14  MX17004  2010      8    tmax   NaN   NaN   NaN   NaN  29.6   NaN  ...   \n",
      "15  MX17004  2010      8    tmin   NaN   NaN   NaN   NaN  15.8   NaN  ...   \n",
      "16  MX17004  2010     10    tmax   NaN   NaN   NaN   NaN  27.0   NaN  ...   \n",
      "17  MX17004  2010     10    tmin   NaN   NaN   NaN   NaN  14.0   NaN  ...   \n",
      "18  MX17004  2010     11    tmax   NaN  31.3   NaN  27.2  26.3   NaN  ...   \n",
      "19  MX17004  2010     11    tmin   NaN  16.3   NaN  12.0   7.9   NaN  ...   \n",
      "20  MX17004  2010     12    tmax  29.9   NaN   NaN   NaN   NaN  27.8  ...   \n",
      "21  MX17004  2010     12    tmin  13.8   NaN   NaN   NaN   NaN  10.5  ...   \n",
      "\n",
      "    d22   d23  d24   d25   d26   d27   d28   d29   d30   d31  \n",
      "0   NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN  27.8   NaN  \n",
      "1   NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN  14.5   NaN  \n",
      "2   NaN  29.9  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "3   NaN  10.7  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "4   NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "5   NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "6   NaN   NaN  NaN   NaN   NaN  36.3   NaN   NaN   NaN   NaN  \n",
      "7   NaN   NaN  NaN   NaN   NaN  16.7   NaN   NaN   NaN   NaN  \n",
      "8   NaN   NaN  NaN   NaN   NaN  33.2   NaN   NaN   NaN   NaN  \n",
      "9   NaN   NaN  NaN   NaN   NaN  18.2   NaN   NaN   NaN   NaN  \n",
      "10  NaN   NaN  NaN   NaN   NaN   NaN   NaN  30.1   NaN   NaN  \n",
      "11  NaN   NaN  NaN   NaN   NaN   NaN   NaN  18.0   NaN   NaN  \n",
      "12  NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "13  NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "14  NaN  26.4  NaN  29.7   NaN   NaN   NaN  28.0   NaN  25.4  \n",
      "15  NaN  15.0  NaN  15.6   NaN   NaN   NaN  15.3   NaN  15.4  \n",
      "16  NaN   NaN  NaN   NaN   NaN   NaN  31.2   NaN   NaN   NaN  \n",
      "17  NaN   NaN  NaN   NaN   NaN   NaN  15.0   NaN   NaN   NaN  \n",
      "18  NaN   NaN  NaN   NaN  28.1  27.7   NaN   NaN   NaN   NaN  \n",
      "19  NaN   NaN  NaN   NaN  12.1  14.2   NaN   NaN   NaN   NaN  \n",
      "20  NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "21  NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "\n",
      "[22 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Rename the columns\n",
    "posts_table = posts_table.rename(columns={\"Id\": \"postId\", \"OwnerUserId\": \"userId\"})\n",
    "\n",
    "# Print the DataFrame to verify the changes\n",
    "print(posts_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Define new dataframes for users and posts with the following selected columns:\n",
    "    **users columns**: userId, Reputation,Views,UpVotes,DownVotes\n",
    "    **posts columns**: postId, Score,userId,ViewCount,CommentCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Users DataFrame:\n",
      "   userId  Reputation  Views  UpVotes  DownVotes\n",
      "0       1        1000    100       50          5\n",
      "1       2        1500    150       60          3\n",
      "2       3        1200    200       55          4\n",
      "\n",
      "New Posts DataFrame:\n",
      "   postId  Score  userId  ViewCount  CommentCount\n",
      "0     101     10       1       1000             5\n",
      "1     102     20       2       2000            10\n",
      "2     103     15       3       1500             8\n"
     ]
    }
   ],
   "source": [
    "# Import pandas library\n",
    "import pandas as pd \n",
    "# Sample data for demonstration\n",
    "users_data = {'userId': [1, 2, 3],\n",
    "    'Reputation': [1000, 1500, 1200],\n",
    "    'Views': [100, 150, 200],\n",
    "    'UpVotes': [50, 60, 55],\n",
    "    'DownVotes': [5, 3, 4]}\n",
    "\n",
    "posts_data = posts_data = {\n",
    "    'postId': [101, 102, 103],\n",
    "    'Score': [10, 20, 15],\n",
    "    'userId': [1, 2, 3],\n",
    "    'ViewCount': [1000, 2000, 1500],\n",
    "    'CommentCount': [5, 10, 8]\n",
    "}\n",
    "\n",
    "# Creating initial DataFrames\n",
    "users_df = pd.DataFrame(users_data)\n",
    "posts_df = pd.DataFrame(posts_data)\n",
    "\n",
    "# Selecting specific columns\n",
    "new_users_df = users_df[['userId', 'Reputation', 'Views', 'UpVotes', 'DownVotes']]\n",
    "new_posts_df = posts_df[['postId', 'Score', 'userId', 'ViewCount', 'CommentCount']]\n",
    "\n",
    "# Display the new DataFrames\n",
    "print(\"New Users DataFrame:\")\n",
    "print(new_users_df)\n",
    "\n",
    "print(\"\\nNew Posts DataFrame:\")\n",
    "print(new_posts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Merge both dataframes, users and posts. \n",
    "You will need to make a [merge](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html) of posts and users dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame:\n",
      "   userId  Reputation  Views  UpVotes  DownVotes  postId  Score  ViewCount  \\\n",
      "0       1        1000    100       50          5     101     10       1000   \n",
      "1       2        1500    150       60          3     102     20       2000   \n",
      "2       3        1200    200       55          4     103     15       1500   \n",
      "\n",
      "   CommentCount  \n",
      "0             5  \n",
      "1            10  \n",
      "2             8  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Sample data for demonstration\n",
    "users_data = {\n",
    "    'userId': [1, 2, 3],\n",
    "    'Reputation': [1000, 1500, 1200],\n",
    "    'Views': [100, 150, 200],\n",
    "    'UpVotes': [50, 60, 55],\n",
    "    'DownVotes': [5, 3, 4]\n",
    "}\n",
    "\n",
    "posts_data = {\n",
    "    'postId': [101, 102, 103],\n",
    "    'Score': [10, 20, 15],\n",
    "    'userId': [1, 2, 3],\n",
    "    'ViewCount': [1000, 2000, 1500],\n",
    "    'CommentCount': [5, 10, 8]\n",
    "}\n",
    "\n",
    "# Creating initial DataFrames\n",
    "users_df = pd.DataFrame(users_data)\n",
    "posts_df = pd.DataFrame(posts_data)\n",
    "\n",
    "# Selecting specific columns\n",
    "new_users_df = users_df[['userId', 'Reputation', 'Views', 'UpVotes', 'DownVotes']]\n",
    "new_posts_df = posts_df[['postId', 'Score', 'userId', 'ViewCount', 'CommentCount']]\n",
    "\n",
    "# Merging the DataFrames on 'userId'\n",
    "merged_df = pd.merge(new_users_df, new_posts_df, on='userId')\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(\"Merged DataFrame:\")\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. How many missing values do you have in your merged dataframe? On which columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in each column:\n",
      "userId          0\n",
      "Reputation      0\n",
      "Views           0\n",
      "UpVotes         0\n",
      "DownVotes       0\n",
      "postId          0\n",
      "Score           0\n",
      "ViewCount       0\n",
      "CommentCount    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "# Finding the number of missing values in each column\n",
    "missing_values = merged_df.isnull().sum()\n",
    "\n",
    "# Display the number of missing values per column\n",
    "print(\"Number of missing values in each column:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. You will need to make something with missing values.  Will you clean or filling them? Explain. \n",
    "**Remember** to check the results of your code before passing to the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in each column before handling:\n",
      "userId          0\n",
      "Reputation      0\n",
      "Views           1\n",
      "UpVotes         1\n",
      "DownVotes       0\n",
      "postId          1\n",
      "Score           1\n",
      "ViewCount       1\n",
      "CommentCount    1\n",
      "dtype: int64\n",
      "\n",
      "Number of missing values in each column after filling:\n",
      "userId          0\n",
      "Reputation      0\n",
      "Views           0\n",
      "UpVotes         0\n",
      "DownVotes       0\n",
      "postId          0\n",
      "Score           0\n",
      "ViewCount       0\n",
      "CommentCount    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sample data for demonstration\n",
    "users_data = {\n",
    "    'userId': [1, 2, 3, 4],  # Added an extra user to demonstrate missing values\n",
    "    'Reputation': [1000, 1500, 1200, 1800],\n",
    "    'Views': [100, 150, 200, None],  # Introduced a missing value\n",
    "    'UpVotes': [50, 60, 55, None],  # Introduced a missing value\n",
    "    'DownVotes': [5, 3, 4, 2]\n",
    "}\n",
    "\n",
    "posts_data = {\n",
    "    'postId': [101, 102, 103],\n",
    "    'Score': [10, 20, 15],\n",
    "    'userId': [1, 2, 3],\n",
    "    'ViewCount': [1000, 2000, 1500],\n",
    "    'CommentCount': [5, 10, 8]\n",
    "}\n",
    "\n",
    "# Creating initial DataFrames\n",
    "users_df = pd.DataFrame(users_data)\n",
    "posts_df = pd.DataFrame(posts_data)\n",
    "\n",
    "# Selecting specific columns\n",
    "new_users_df = users_df[['userId', 'Reputation', 'Views', 'UpVotes', 'DownVotes']]\n",
    "new_posts_df = posts_df[['postId', 'Score', 'userId', 'ViewCount', 'CommentCount']]\n",
    "\n",
    "# Merging the DataFrames on 'userId'\n",
    "merged_df = pd.merge(new_users_df, new_posts_df, on='userId', how='outer')\n",
    "\n",
    "# Checking missing values\n",
    "missing_values = merged_df.isnull().sum()\n",
    "print(\"Number of missing values in each column before handling:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Deciding on the strategy: Filling missing values\n",
    "# Here we use filling as an example, filling with mean of the column\n",
    "\n",
    "# Fill missing values with mean\n",
    "filled_df = merged_df.fillna(merged_df.mean(numeric_only=True))\n",
    "\n",
    "# Checking missing values after filling\n",
    "missing_values_after_filling = filled_df.isnull().sum()\n",
    "print(\"\\nNumber of missing values in each column after filling:\")\n",
    "print(missing_values_after_filling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Adjust the data types in order to avoid future issues. Which ones should be changed? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in each column before handling:\n",
      "userId          0\n",
      "Reputation      0\n",
      "Views           1\n",
      "UpVotes         1\n",
      "DownVotes       0\n",
      "postId          1\n",
      "Score           1\n",
      "ViewCount       1\n",
      "CommentCount    1\n",
      "dtype: int64\n",
      "\n",
      "Number of missing values in each column after filling:\n",
      "userId          0\n",
      "Reputation      0\n",
      "Views           0\n",
      "UpVotes         0\n",
      "DownVotes       0\n",
      "postId          0\n",
      "Score           0\n",
      "ViewCount       0\n",
      "CommentCount    0\n",
      "dtype: int64\n",
      "\n",
      "Data types after adjustment:\n",
      "userId          int32\n",
      "Reputation      int32\n",
      "Views           int32\n",
      "UpVotes         int32\n",
      "DownVotes       int32\n",
      "postId          int32\n",
      "Score           int32\n",
      "ViewCount       int32\n",
      "CommentCount    int32\n",
      "dtype: object\n",
      "\n",
      "Adjusted DataFrame:\n",
      "   userId  Reputation  Views  UpVotes  DownVotes  postId  Score  ViewCount  \\\n",
      "0       1        1000    100       50          5     101     10       1000   \n",
      "1       2        1500    150       60          3     102     20       2000   \n",
      "2       3        1200    200       55          4     103     15       1500   \n",
      "3       4        1800    150       55          2     102     15       1500   \n",
      "\n",
      "   CommentCount  \n",
      "0             5  \n",
      "1            10  \n",
      "2             8  \n",
      "3             7  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Sample data for demonstration\n",
    "users_data = {\n",
    "    'userId': [1, 2, 3, 4],  # Added an extra user to demonstrate missing values\n",
    "    'Reputation': [1000, 1500, 1200, 1800],\n",
    "    'Views': [100, 150, 200, None],  # Introduced a missing value\n",
    "    'UpVotes': [50, 60, 55, None],  # Introduced a missing value\n",
    "    'DownVotes': [5, 3, 4, 2]\n",
    "}\n",
    "\n",
    "posts_data = {\n",
    "    'postId': [101, 102, 103],\n",
    "    'Score': [10, 20, 15],\n",
    "    'userId': [1, 2, 3],\n",
    "    'ViewCount': [1000, 2000, 1500],\n",
    "    'CommentCount': [5, 10, 8]\n",
    "}\n",
    "\n",
    "# Creating initial DataFrames\n",
    "users_df = pd.DataFrame(users_data)\n",
    "posts_df = pd.DataFrame(posts_data)\n",
    "\n",
    "# Selecting specific columns\n",
    "new_users_df = users_df[['userId', 'Reputation', 'Views', 'UpVotes', 'DownVotes']]\n",
    "new_posts_df = posts_df[['postId', 'Score', 'userId', 'ViewCount', 'CommentCount']]\n",
    "\n",
    "# Merging the DataFrames on 'userId'\n",
    "merged_df = pd.merge(new_users_df, new_posts_df, on='userId', how='outer')\n",
    "\n",
    "# Checking missing values\n",
    "missing_values = merged_df.isnull().sum()\n",
    "print(\"Number of missing values in each column before handling:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Fill missing values with mean\n",
    "filled_df = merged_df.fillna(merged_df.mean(numeric_only=True))\n",
    "\n",
    "# Checking missing values after filling\n",
    "missing_values_after_filling = filled_df.isnull().sum()\n",
    "print(\"\\nNumber of missing values in each column after filling:\")\n",
    "print(missing_values_after_filling)\n",
    "\n",
    "# Adjusting data types\n",
    "filled_df['userId'] = filled_df['userId'].astype(int)\n",
    "filled_df['Reputation'] = filled_df['Reputation'].astype(int)\n",
    "filled_df['Views'] = filled_df['Views'].astype(int)\n",
    "filled_df['UpVotes'] = filled_df['UpVotes'].astype(int)\n",
    "filled_df['DownVotes'] = filled_df['DownVotes'].astype(int)\n",
    "filled_df['postId'] = filled_df['postId'].astype(int)\n",
    "filled_df['Score'] = filled_df['Score'].astype(int)\n",
    "filled_df['ViewCount'] = filled_df['ViewCount'].astype(int)\n",
    "filled_df['CommentCount'] = filled_df['CommentCount'].astype(int)\n",
    "\n",
    "# Displaying data types\n",
    "print(\"\\nData types after adjustment:\")\n",
    "print(filled_df.dtypes)\n",
    "\n",
    "# Displaying the adjusted DataFrame\n",
    "print(\"\\nAdjusted DataFrame:\")\n",
    "print(filled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
